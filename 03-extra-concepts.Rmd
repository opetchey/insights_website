# Additional concepts


## Modes of data analysis

Talk about these three:
* Exploration of patterns
* Prediction of patterns
* Confirmation of causes
Look here for inspiration, of some kind.
https://dynamicecology.wordpress.com/2013/10/16/in-praise-of-exploratory-statistics/


## Interoperability

Countries in the fao polity study

https://www.r-bloggers.com/taxadb-a-high-performance-local-taxonomic-database-interface/

### Standardising terms

It's certainly nice to know that we accurately entered the prey species names, in the sense that they match the names of known prey species. Doing so will also ensure that our results could be compared with and combined with other studies of moth species (put another way, we would have assured our data are *interoperable* with other studies involving these moth species). To do this, we can use a very nice set of packages that make the whole process a total breeze. Let's try this for the first ten species in the dataset. Note that the first line below installs the __taxize__ add-on package, and is commented out as we only need to run it once).

```{r eval = FALSE}
# install.packages("taxize")
# the previous line was commented out. Uncomment it by removing
# the comment # if you want to run it.
library(taxize) # load the package
some_species_names <- slice(dd, 1:10) %>%
  pull(Species) # get first ten species
# query the online database of species names
species_names_reports <- gnr_resolve(some_species_names,
                                     best_match_only = TRUE)
species_names_reports
```

In this report, the final column gives a quick indication of how well the moth species name in the dataset matched a known species name. A score of 1 is the highest match, 0 is the lowest. This tells us that *Ethmia bipunctella* and *Bradycellus verbasci* in the dataset correspond to known species---their matching score in the final column is 0.988. The third species in the dataset, however is *Hoplodrina ambigua/ superstes* and cannot be well matched to an individual known species---it has a score of 0.75. Likely this entry in the dataset corresponds with the text in the paper "When the same haplotype matched more than one species, we ... classified them into a species group". I.e. *H. ambigua* and *H. superstes* could not be distinguished and so were treated as a species group. (It takes a while to make these queries, so we don't run one for every moth species name in the dataset.) There is lots more one can do with species names, but it's a bit beyond the scope of this book, so we now move on.



## Lurking variables


State that we simulated this data. Make the code available on r4all.

```{r echo=FALSE}
# Code from here: https://bookdown.org/ajkurz/Statistical_Rethinking_recoded/multivariate-linear-models.html#masked-relationship
N   <- 400   # number of cases
rho <- .8      # correlation between x_pos and x_neg
set.seed(141)  # setting the seed makes the results reproducible
dd <- 
  tibble(x1 = rnorm(N),                            
         x2 = rnorm(N, rho*x1, sqrt(1 - rho^2)),  
         y     = rnorm(N, x1 - x2))               
```

```{r}
dd
```

```{r masked-rels-1, fig.cap='(a and b) Little evidence of a relationship between the response variable *y* and either of the two explanatory variables *x1*, or *x2*. (c) Strong correlation between the two explanatory variables *x1* and *x2*', out.width='50%', fig.asp=.75, fig.align='center', echo=FALSE, warning=FALSE}
library(patchwork)
p1 <- ggplot(dd, aes(x=x1, y=y)) +
  geom_point()
p2 <- ggplot(dd, aes(x=x2, y=y)) +
  geom_point()
p3 <- ggplot(dd, aes(x=x1, y=x2)) +
  geom_point()
p1 + p2 + p3
```


```{r}
dd <- mutate(dd,
            x1_cut = cut(x1, 10),
            x2_cut = cut(x2, 10))
```

```{r masked-rels-2, fig.cap='The positive relationship between the response variable (*y*) and one of the explanatory variables (*x1*) is visible because each facet shows a relatively small range of variation in the other explanatory variable (*x2*).', out.width='50%', fig.asp=.75, fig.align='center', echo=FALSE, warning=FALSE}
ggplot(dd, aes(x=x1, y=y)) +
  geom_point() +
  facet_wrap(~x2_cut, scales = "free", nrow = 2)

```

```{r masked-rels-3, fig.cap='The same as the previous figure, but with the explanatory variables switched, so that we see the negative relationship between *y* and *x2*.', out.width='50%', fig.asp=.75, fig.align='center', echo=FALSE, warning=FALSE}
ggplot(dd, aes(x=x2, y=y)) +
  geom_point() +
  facet_wrap(~x1_cut, scales = "free", nrow = 2)
```

Conditional plots. How can one "account for" the other explanatory variable? Hold the second explanatory variable constant, or at least relatively constant.

Correlated explanatory variables.



We can easily think of situations that are not so amenable to the approaches you learned in this book. This does not mean that the approaches are not useful or important. They are foundational. And therefore to be built on.

One example of such a situation is if we have two continuous explanatory variables that are relatively strongly correlated with each other. And we are looking at how they are related to a response variable.  It is quite possible that we see a positive relationship between one explanatory variable and the response variable, when the relationship is in fact negative. We can see the negative relationship only once we have accounted for the other explanatory variable. If this sounds a bit concerning then good... it is. It illustrates how very important is checking for, and understanding implications of, correlations among explanatory variables.


## Influence and outliers

We sometimes observe one or a few data point that are quite different from all others. How can we tell if they are so different that we should treat them differently? How can we know if they are different and likely to have high influence on our conclusions? What influence on our conclusions (analysis) does an individual data point have? This will depend on various things, including: 1) number of other data points, with more other data points resulting in any individual one having less influence; 2)
the value of the data point (y-value)... large ones (either in the positive or negative direction) tend to have larger influence; 2) the x value of the data point... where larger ones (in positive or negative direction) have more influence.
We can think of this by anology with a children's playground toy... the seesaw. Can you put together what I write above, and this toy? How would the analogy work?

## Transformations



## Interactions

https://github.com/opetchey/insights1_edition1/issues/4

## Distributions

https://blog.cloudera.com/blog/2015/12/common-probability-distributions-the-data-scientists-crib-sheet/

